{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e08c724-dc0b-4429-b0ff-af1550c4165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32d3069-2711-4167-852e-1e566eaf6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274a093b-1b5a-40ca-ad48-8ebf500aefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131c88f4-8335-45d0-9765-195c75876b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('datasets/squad_train.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8f26b4-5e81-478a-9ae1-45a9dbab5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc759c6-d897-4c42-8624-e08d1184b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "start_positions = []\n",
    "end_positions = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42d90d9-2c5a-49af-b707-855e7b6ed0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 128 \n",
    "max_chunk_length = 384 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a784898b-b95c-49fa-9dd0-e2034eb86487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  68%|██████████████████████████████████████                  | 59577/87599 [14:17<06:43, 69.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m     16\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m     17\u001b[0m         question,\n\u001b[0;32m     18\u001b[0m         chunk,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     )\n\u001b[1;32m---> 27\u001b[0m     input_id \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     28\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Tokenize the chunk\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing dataset\"):\n",
    "    question = row['question']\n",
    "    context = row['context']\n",
    "    answer = row['answers']['text'][0]  # Assuming we take the first answer\n",
    "\n",
    "    # Tokenize the answer separately\n",
    "    answer_tokens = tokenizer.tokenize(answer)\n",
    "\n",
    "    # Split context into chunks with sliding window approach\n",
    "    chunks = []\n",
    "    for i in range(0, len(context), stride):\n",
    "        chunk = context[i:i + max_chunk_length]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            question,\n",
    "            chunk,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            truncation='only_second',\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        input_id = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "\n",
    "        # Tokenize the chunk\n",
    "        chunk_tokens = tokenizer.tokenize(chunk)\n",
    "\n",
    "        # Find the start and end positions of the answer in the chunk\n",
    "        try:\n",
    "            token_start_index = chunk_tokens.index(answer_tokens[0])\n",
    "            token_end_index = token_start_index + len(answer_tokens) - 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # Adjust the positions to account for the question tokens\n",
    "        token_start_index += len(tokenizer.tokenize(question)) + 2  # +2 for [CLS] and [SEP]\n",
    "        token_end_index += len(tokenizer.tokenize(question)) + 2\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        start_positions.append(token_start_index)\n",
    "        end_positions.append(token_end_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c4f6d-259c-4498-8a5f-77f845fe4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.stack(input_ids)\n",
    "attention_masks = torch.stack(attention_masks)\n",
    "start_positions = torch.tensor(start_positions)\n",
    "end_positions = torch.tensor(end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93229e-cb59-49ed-9387-47463aac3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = TensorDataset(input_ids, attention_masks, start_positions, end_positions)\n",
    "train_dataloader = DataLoader(dataset, sampler=RandomSampler(dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23567ec-8e54-4477-a02a-7bff2174a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef197546-2947-4f32-b0aa-b2a93fcdbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8bc396-1884-453f-b18d-6719fc0c5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask = batch[1].to(device)\n",
    "        b_start_positions = batch[2].to(device)\n",
    "        b_end_positions = batch[3].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            outputs = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_attention_mask,\n",
    "                start_positions=b_start_positions,\n",
    "                end_positions=b_end_positions\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            if 'CUDA out of memory' in str(e):\n",
    "                print(\"CUDA out of memory. Switching to CPU...\")\n",
    "                device = torch.device('cpu')\n",
    "                model.to(device)\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    attention_mask=b_attention_mask,\n",
    "                    start_positions=b_start_positions,\n",
    "                    end_positions=b_end_positions\n",
    "                )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save checkpoint after each epoch\n",
    "    checkpoint_path = f\"checkpoint-epoch-{epoch + 1}.pt\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae356ab8-727e-44a8-8122-abbde19ccd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = \"distilbert_qa_finetuned.pt\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Model saved at {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98d258-d534-478d-9167-e2a0352f3c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-kernel",
   "language": "python",
   "name": "notebooks-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
